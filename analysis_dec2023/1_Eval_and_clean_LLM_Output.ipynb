{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Evaluating LLM performance in Wetlands Tracker\n",
    "\n",
    "January 29 2024\n",
    "\n",
    "\n",
    "This notebook contains a workflow to load data extracted by the main branch of this repository - the wetlands-tracker - and perform the following:\n",
    "\n",
    "- Report overall data quality.\n",
    "- Compare LLM responses with Regex.\n",
    "- Print out random LLM samples for human eval.\n",
    "- Use a fine-tuned OpenAI model to regenerate responses.\n",
    "- Categorize the responses using `.json` files generated during runtime, or pre-loaded from the repository.\n",
    "- Export a cleaner version of the `wetland_impact` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import tiktoken  # Ensure you have this package installed\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import re\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of errors to track.\n",
    "\n",
    "\n",
    "1. Step 1: Gets these tables from data schema:\n",
    "\n",
    "    * raw_df\n",
    "\n",
    "    * validation_df\n",
    "\n",
    "    * wetland_df\n",
    "\n",
    "    * embed_df\n",
    "    \n",
    "2. Step 2: errors in **RAW_DF**\n",
    "\n",
    "    * Number of 'unknowns' by column/table\n",
    "\n",
    "    * Scraping/URL errors\n",
    "\n",
    "    * len(longitude list) == len(latitude list) for same noticeID\n",
    "    \n",
    "    * No. of special notices\n",
    "\n",
    "\n",
    "3.  Step 3: errors in **WEtland and Validation df**\n",
    "\n",
    "    * API based errors (in LLMfunctions.py, get requests error (404, 202 etc.) and put in column)\n",
    "\n",
    "    * check rows where wetland_impact_unit = 0\n",
    "\n",
    "    * check rows where regex and OPenAI differ (NOTE - ONLY FOR FUTURE NOTICES)\n",
    "    \n",
    "    * Value counts/table of different impact units+types\n",
    "\n",
    "4. Step 4: errors in embed_df\n",
    "\n",
    "    * Total project area - check for zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the working directory\n",
    "os.chdir(r'D:\\Work\\Georgetown\\acad\\mdi\\usace\\usace_analysis')\n",
    "\n",
    "# Read parquet\n",
    "#read\n",
    "val_df = pd.read_parquet('val_df_5jan.parquet')\n",
    "wet_df = pd.read_parquet('wet_df_5jan.parquet')\n",
    "loc_df = pd.read_parquet('loc_df_5jan.parquet')\n",
    "emb_df = pd.read_parquet('emb_df_5jan.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating LLM responses against Regex\n",
    "\n",
    "There are two methods:\n",
    "\n",
    "1. Convert to a symmetrical JSON schema, and compare each value of key.\n",
    "\n",
    "2. Check the raw string distances of the text captured in the 'values' by the LLM and regex dictionaries.\n",
    "\n",
    "Use the Levenshtein distance to quantify distance of the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Function to calculate unknown and NaN counts and percentages\n",
    "# def calculate_unknown_nan(df):\n",
    "#     results = []\n",
    "\n",
    "#     for column in df.columns:\n",
    "#         unknown_count = (df[column] == 'unknown').sum()\n",
    "#         nan_count = df[column].isna().sum()\n",
    "#         total_count = len(df)\n",
    "        \n",
    "#         unknown_percent = (unknown_count / total_count) * 100\n",
    "#         nan_percent = (nan_count / total_count) * 100\n",
    "\n",
    "#         results.append({\n",
    "#             'Column': column,\n",
    "#             'Unknown Count': unknown_count,\n",
    "#             'Unknown Percent': unknown_percent,\n",
    "#             'NaN Count': nan_count,\n",
    "#             'NaN Percent': nan_percent\n",
    "#         })\n",
    "\n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "# # Generate the table\n",
    "# unknown_nan_table = calculate_unknown_nan(main_df)\n",
    "# # unknown_nan_table\n",
    "\n",
    "# main_df['len1'] = main_df.pdf_impact.apply(lambda x: len(x))\n",
    "# main_df['len2'] = main_df.wetland_llm_dict.apply(lambda x: len(x))\n",
    "\n",
    "# main_df[['pdf_impact', 'wetland_llm_dict', 'lev_distance', 'len1', 'len2']][(main_df['len1']> 7) & (main_df['len2']> 16)].sort_values(by='lev_distance').tail(1).values\n",
    "\n",
    "# def determine_message(row):\n",
    "#     if row['len1'] == 2 and row['len2'] == 16:\n",
    "#         return 'Both returned NAs'\n",
    "#     elif row['len1'] == 2 and row['len2'] > 16:\n",
    "#         return 'Regex returned NAs'\n",
    "#     elif row['len2'] == 16  and row['len1'] != 2:\n",
    "#         return 'OpenAI returned NAs'\n",
    "#     else:\n",
    "#         return 'Both returned objects'\n",
    "\n",
    "# # Apply the function to each row\n",
    "# main_df['message'] = main_df.apply(determine_message, axis=1)\n",
    "# main_df.message.value_counts()\n",
    "\n",
    "# df = main_df[['web_title', 'pdf_impact', 'wetland_llm_dict', 'lev_distance', 'len1', 'len2']].copy()\n",
    "\n",
    "\n",
    "# df.sort_values(by='len1').head(10)\n",
    "\n",
    "# fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "\n",
    "# df[(df.len1<2000)].len1.hist(color='red', alpha=.6, bins=30, legend=True)\n",
    "\n",
    "# df[(df.len2<2000)].len2.hist(color='blue', alpha=.5, bins=30, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite prompt + Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = \"\"\" You will get a passage about a project. Use the function schema to get a dictionary. \n",
    "            For each wetland, provide its type or descriptor, the area it occupies in acres,\n",
    "            and the duration of its impact (e.g., 'permanent' or 'temporary'). \n",
    "            You should focus on sentences which contain information on area or (linear feet) and wetland type impacted.\n",
    "            The priority is the breakdown by wetland type. \n",
    "            Only record 'impact_duration' as 'permanent' or 'temporary' if it appears in the same sentence as 'wetland_type' \n",
    "            and 'area', otherwise write 'unknown'. \n",
    "            Some passages describe multiple projects, and sequentially describe the wetland impacts for each project.            \n",
    "            Keywords like 'including' or 'of which', or parentheses '()' may indicate nested projects - Do not double count impacts.\n",
    "            The impact_type for a wetland is usually loss or damage. \n",
    "            Sometimes words like positive, beneficial, restoration etc. will indicate a positive or neutral impact, record it.\n",
    "            Take a deep breath, and work on this problem step-by-step. \n",
    "\n",
    "            Here is the text: \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt2 = \"\"\" You will get a passage about a project. Use the function schema to get a dictionary. \n",
    "Identify Wetlands and Impacts: Look for sentences detailing the wetland/water/land type and the impacts. Record the type, quantity, and unit. There may be multiple impacts.\n",
    "Determine Impact Duration: Mark 'permanent' or 'temporary' if mentioned with wetland type and area; else, write 'unknown'.\n",
    "Assess Impact Type: Record the type of impact being described, preferably recording the exact term.\n",
    "Avoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.Some passages describe multiple projects, and/or sequentially describe the wetland impacts for each project.            \n",
    "Keywords like 'including' or 'of which', or parentheses '()' may indicate nested projects.\n",
    "Create a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\n",
    "Take a deep breath, and work on this problem step-by-step. Here is the text: \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_prompt = \"\"\"Your task is to Extract information from a project description to create a structured dictionary, following the provided JSON schema. Focus on identifying wetland impacts based on the given criteria.\n",
    "\n",
    "JSON Schema Overview:\n",
    "\n",
    "wetland_type: Type or descriptor of the wetland (e.g., swamp, marsh).\n",
    "impact_quantity: Numeric value of the impacted area.\n",
    "impact_unit: Units of measurement (acres, sq. feet, linear feet).\n",
    "impact_duration: Duration of impact (permanent, temporary, unknown).\n",
    "impact_type: Nature of impact (harmful, beneficial, unknown).\n",
    "Instructions:\n",
    "\n",
    "Identify Wetlands and Impacts: Look for sentences detailing the wetland/water/land type and the impacts. Record the type, quantity, and unit. There may be multiple impacts.\n",
    "Determine Impact Duration: Mark 'permanent' or 'temporary' if mentioned with wetland type and area; else, write 'unknown'.\n",
    "Assess Impact Type: Identify if the impact is harmful, beneficial, or unknown.\n",
    "Avoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.\n",
    "Create a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\n",
    "Example Input:\n",
    "'The project will affect 3.5 acres of marshland permanently, leading to habitat loss...'\n",
    "\n",
    "Expected Output:\n",
    "{'wetlands': [{'wetland_type': 'marshland', 'impact_quantity': '3.5', 'impact_unit': 'acres', 'impact_duration': 'permanent', 'impact_type': 'loss'}]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat completion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(GPT_MODEL, messages, API_KEY, functions=None, function_call=None):\n",
    "    \"\"\"\n",
    "    This function makes a POST request to the OpenAI Chat Completion API, sending a JSON payload \n",
    "    that includes the GPT model, a series of messages. It is designed to retry up to three times with \n",
    "    exponential backoff in case of failures. \n",
    "\n",
    "    Parameters:\n",
    "    GPT_MODEL (str): The identifier of the GPT model to be used for generating responses.\n",
    "    messages (list): A list of message dictionaries, where each dictionary represents a single exchange \n",
    "                     within the chat. Each message has a 'role' (either 'user' or 'assistant') and \n",
    "                     'content' (the message text).\n",
    "    API_KEY (str): The API key for authentication with the OpenAI API.\n",
    "    functions (list, optional): A list of additional functions to be used along with the GPT model. \n",
    "                                Default is None.\n",
    "    function_call (dict, optional): A dictionary representing a function call, including function name \n",
    "                                    and parameters. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    requests.models.Response: The response object from the API call if successful.\n",
    "    Exception: The exception object if the API call fails.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + API_KEY,\n",
    "    }\n",
    "    json_data = {\"model\": GPT_MODEL, \"messages\": messages, \"temperature\": 0}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "### Function 1 - Wetland impact\n",
    "\n",
    "main_func = [\n",
    "\n",
    "            { # function to capture wetland impacts\n",
    "              \"name\": \"wetland_analysis\",\n",
    "              \"description\": \"\"\"Get attributes for project, wetlands, area and duration.\"\"\",\n",
    "              \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                   \"wetlands\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"Array containing information about project and impact on wetlands etc..\",\n",
    "                    \"items\": {\n",
    "                      \"type\": \"object\",\n",
    "                      \"properties\": {\n",
    "                        \"wetland_type\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The type or descriptor of the wetland, waters, waterbottoms, swamp, marsh etc.\"\n",
    "                        },\n",
    "\n",
    "                          \"impact_quantity\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"The quantity of the wetland, stream or land impacted. Only numeric.\"\n",
    "                        },\n",
    "                          \n",
    "                        \"impact_unit\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"enum\": [\"acres\", \"sq. feet\", \"linear feet\"],\n",
    "                          \"description\": \"The units of the measurement for the impacted area of the wetland. Only text.\"\n",
    "                        },\n",
    "\n",
    "                        \"impact_duration\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"enum\": [\"permanent\", \"temporary\", \"unknown\"],\n",
    "                          \"description\": \"Duration of impact or loss of the wetland, e.g., 'permanent' or 'temporary'. Write 'Unknown' if no descriptor in same sentence.\"\n",
    "                        },\n",
    "                        \"impact_type\": {\n",
    "                          \"type\": \"string\",\n",
    "                          \"description\": \"Whether project impact is harmful, beneficial or unknown. \"\n",
    "                        }\n",
    "                          \n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def openAIfunc_wetland(input_text,  API_KEY, GPT_MODEL, prompt):\n",
    "    \n",
    "    messages = []\n",
    "   # messages.append({\"role\": \"system\", \"content\": \"Work step by step.\"})   # POTENTIAL ERROR\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt + input_text                \n",
    "                    })\n",
    "\n",
    "# https://arxiv.org/pdf/2309.03409.pdf\n",
    "    chat_response = chat_completion_request(GPT_MODEL,\n",
    "        messages, API_KEY, functions=main_func, function_call={\"name\": \"wetland_analysis\"} )\n",
    "\n",
    "    func_response = chat_response.json()[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"]\n",
    "\n",
    "    # Convert the stringified JSON to a Python dictionary\n",
    "#     func_response_dict = json.loads(func_response)\n",
    "\n",
    "    # except (KeyError, json.JSONDecodeError) as e:\n",
    "    # print(f\"An error occurred: {e}\")\n",
    "    # func_response_dict = {}\n",
    "\n",
    "    return func_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_id = 'ft:gpt-3.5-turbo-0613:eidc-mdi-georgetown:usace-json:8ait0mXa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"Initially, the authorized project proposed that  approximately 7.169 acres of  forested swamp wetlands would be temporarily impacted during projec t construction but were reduced to 5.873 acres.  Moreover, the aut horized project also propos ed temporary impacts to approximately 5.755 acres of herbaceous wetl ands but was increased to 6.284 acres during project construction.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = openAIfunc_wetland(input_text=text1, API_KEY=OPENAI_API_KEY, GPT_MODEL = fine_tuned_model_id)\n",
    "chat_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dec 2023 version\n",
    "\n",
    "### - Human prompt, GPT-3.5-turbo-0613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"wetlands\": [\\n    {\\n      \"wetland_type\": \"forested swamp\",\\n      \"impact_quantity\": \"5.873\",\\n      \"impact_unit\": \"acres\",\\n      \"impact_duration\": \"temporary\",\\n      \"impact_type\": \"loss\"\\n    },\\n    {\\n      \"wetland_type\": \"herbaceous wetlands\",\\n      \"impact_quantity\": \"6.284\",\\n      \"impact_unit\": \"acres\",\\n      \"impact_duration\": \"temporary\",\\n      \"impact_type\": \"loss\"\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response = openAIfunc_wetland(input_text=text1, API_KEY=OPENAI_API_KEY, \n",
    "                                   GPT_MODEL = 'gpt-3.5-turbo-0613', prompt=human_prompt)\n",
    "chat_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - LLM prompt, GPT-3.5-turbo-0613-ft-eidc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"wetlands\": [\\n    {\\n      \"wetland_type\": \"forested swamp wetlands\",\\n      \"impact_quantity\": \"5.873\",\\n      \"impact_unit\": \"acres\",\\n      \"impact_duration\": \"temporary\",\\n      \"impact_type\": \"loss\"\\n    },\\n    {\\n      \"wetland_type\": \"herbaceous wetlands\",\\n      \"impact_quantity\": \"6.284\",\\n      \"impact_unit\": \"acres\",\\n      \"impact_duration\": \"temporary\",\\n      \"impact_type\": \"loss\"\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response = openAIfunc_wetland(input_text=text1, API_KEY=OPENAI_API_KEY, \n",
    "                                   GPT_MODEL = fine_tuned_model_id, prompt=human_prompt2)\n",
    "chat_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fine-tuned model on notices from 2020-2024\n",
    "\n",
    "Run it in three batches for efficiency reasons:\n",
    "\n",
    "- From 2021-2024 (~1500)\n",
    "\n",
    "- From 2012 - 2020, batch 1 (~ 2000)\n",
    "\n",
    "- From 2012 - 2020, batch 2 (~ 2200)\n",
    "\n",
    "\n",
    "The code below, however, shows how to do it in two batches. Adapt as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noticeID</th>\n",
       "      <th>pdf_character</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Notice_NO_6585</td>\n",
       "      <td>Clear, grade, excavate, and place approximatel...</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Notice_NO_6578</td>\n",
       "      <td>The applicant proposes to perform dredging ope...</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notice_NO_6594</td>\n",
       "      <td>The applicant has request ed Department of the...</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notice_NO_6589</td>\n",
       "      <td>The applicant is proposing to discharge approx...</td>\n",
       "      <td>2023-10-20</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Notice_NO_6566</td>\n",
       "      <td>The applicant proposes to expand an existing b...</td>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>Notice_NO_6649</td>\n",
       "      <td>Theproposed work is to install and maintain a ...</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>Notice_NO_6650</td>\n",
       "      <td>The applicant seeks authorization to deconstru...</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>Notice_NO_6651</td>\n",
       "      <td>The overall goal of the CAL MB is to re -estab...</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>Notice_NO_6652</td>\n",
       "      <td>The overall goal of the</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639</th>\n",
       "      <td>Notice_NO_6653</td>\n",
       "      <td>The applicant seeks authorization to install 8...</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1543 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            noticeID                                      pdf_character  \\\n",
       "0     Notice_NO_6585  Clear, grade, excavate, and place approximatel...   \n",
       "1     Notice_NO_6578  The applicant proposes to perform dredging ope...   \n",
       "2     Notice_NO_6594  The applicant has request ed Department of the...   \n",
       "3     Notice_NO_6589  The applicant is proposing to discharge approx...   \n",
       "4     Notice_NO_6566  The applicant proposes to expand an existing b...   \n",
       "...              ...                                                ...   \n",
       "6635  Notice_NO_6649  Theproposed work is to install and maintain a ...   \n",
       "6636  Notice_NO_6650  The applicant seeks authorization to deconstru...   \n",
       "6637  Notice_NO_6651  The overall goal of the CAL MB is to re -estab...   \n",
       "6638  Notice_NO_6652                            The overall goal of the   \n",
       "6639  Notice_NO_6653  The applicant seeks authorization to install 8...   \n",
       "\n",
       "     datePublished  year  \n",
       "0       2023-10-30  2023  \n",
       "1       2023-11-09  2023  \n",
       "2       2023-10-16  2023  \n",
       "3       2023-10-20  2023  \n",
       "4       2023-11-21  2023  \n",
       "...            ...   ...  \n",
       "6635    2024-01-01  2024  \n",
       "6636    2023-12-28  2023  \n",
       "6637    2024-01-02  2024  \n",
       "6638    2024-01-02  2024  \n",
       "6639    2024-01-03  2024  \n",
       "\n",
       "[1543 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wet_df = val_df[['noticeID', 'pdf_character', 'datePublished']].copy()\n",
    "\n",
    "# Convert 'datePublished' to datetime\n",
    "wet_df['datePublished'] = pd.to_datetime(wet_df['datePublished'], errors='coerce')\n",
    "wet_df['year'] = wet_df['datePublished'].dt.year\n",
    "\n",
    "# Exclude rows with 'unknown', 'ERROR', NaN in 'pdf_character', and length less than 50 characters\n",
    "wet_df = wet_df[(wet_df.pdf_character != \"unknown\") & \n",
    "                (wet_df.pdf_character.notna()) & \n",
    "                (~wet_df.pdf_character.str.contains(\"ERROR\", na=False))]\n",
    "wet_df['len'] = wet_df.pdf_character.apply(len)\n",
    "wet_df = wet_df[wet_df.len > 50]\n",
    "\n",
    "# Partition the DataFrame into two based on the year\n",
    "wet_df_pre_2020_part1 = wet_df[wet_df.year <= 2020]\n",
    "wet_df_post_2020_part2 = wet_df[wet_df.year > 2020]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▌                                                       | 459/1543 [14:17<56:23,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 459: can only concatenate str (not \"NoneType\") to str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████▉                                                   | 546/1543 [17:14<32:41,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 546: can only concatenate str (not \"NoneType\") to str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▍ | 1513/1543 [56:41<01:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1513: can only concatenate str (not \"NoneType\") to str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████▎| 1530/1543 [56:59<00:14,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1530: can only concatenate str (not \"NoneType\") to str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1543/1543 [57:36<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Function to process and append results to a DataFrame\n",
    "def process_and_append_results(df):\n",
    "    pdf_character_list = df['pdf_character'].tolist()\n",
    "    wetland_llm_results = []\n",
    "\n",
    "    for i, pdf_character in tqdm(enumerate(pdf_character_list), total=len(pdf_character_list)):\n",
    "        try:\n",
    "            result = openAIfunc_wetland(input_text=pdf_character, \n",
    "                                        API_KEY=OPENAI_API_KEY, \n",
    "                                        GPT_MODEL=fine_tuned_model_id, \n",
    "                                        prompt=human_prompt2)\n",
    "            wetland_llm_results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f'Error processing item {i}: {e}')\n",
    "            wetland_llm_results.append(None)\n",
    "\n",
    "    df['wetland_llm_dict'] = wetland_llm_results\n",
    "    return df\n",
    "\n",
    "# Process pre-2020 and post-2020 data\n",
    "wet_df_pre_2020_part1 = process_and_append_results(wet_df_pre_2020_part1)\n",
    "wet_df_pre_2020_part2 = process_and_append_results(wet_df_pre_2020_part2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def dict_to_columns(df_source, dict_col, index_cols):\n",
    "    # Initialize an empty DataFrame for the expanded data\n",
    "    df_main = pd.DataFrame()\n",
    "\n",
    "    # Loop through each row in the source DataFrame\n",
    "    for _, row in df_source.iterrows():\n",
    "        # Extract the item from the dict_col\n",
    "        dict_item = row[dict_col]\n",
    "\n",
    "        # Skip rows where dict_item is None\n",
    "        if dict_item is None:\n",
    "            continue\n",
    "\n",
    "        # Check if the item in dict_col is a string and convert it to a dictionary\n",
    "        if isinstance(dict_item, str):\n",
    "            try:\n",
    "                dict_item = json.loads(dict_item)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding JSON for row: {row}\")\n",
    "                continue\n",
    "\n",
    "        # Use the dictionary to extract data\n",
    "        wetland_dict = dict_item.get('wetlands', [])\n",
    "        ids = {col: row[col] for col in index_cols}\n",
    "\n",
    "        # Create a DataFrame for the wetlands data\n",
    "        wetlands_df = pd.DataFrame(wetland_dict)\n",
    "\n",
    "        # Handle the case where no wetlands data is present\n",
    "#         if wetlands_df.empty:\n",
    "#             wetlands_df = pd.DataFrame(columns=['wetland_type', 'area', 'impact_duration', 'impact_type'])\n",
    "        \n",
    "        # Add ID columns\n",
    "        for col, id_val in ids.items():\n",
    "            wetlands_df[col] = id_val\n",
    "\n",
    "        # Append to the main DataFrame\n",
    "        df_main = pd.concat([df_main, wetlands_df], ignore_index=True)\n",
    "        \n",
    "    return df_main\n",
    "\n",
    "# B. Break out dictionary to columns\n",
    "wetland_impact_df1 = dict_to_columns(df_source=wet_df_pre_2020_part1, dict_col='wetland_llm_dict', index_cols=['noticeID'])\n",
    "wetland_impact_df2 = dict_to_columns(df_source=wet_df_pre_2020_part2, dict_col='wetland_llm_dict', index_cols=['noticeID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wetland_impact_df1.to_parquet('wetland_impacts_pre_2020_1.parquet')\n",
    "\n",
    "wetland_impact_df2.to_parquet('wetland_impacts_pre_2020_2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Notice_NO_4798',\n",
       "        'Construct a 2 5-feet by 30- feet pile-supported boathousewitha 4-feet by 30- feet wharf , and replace approximately 45 linear feet of existing bulkhead, all for private recreational use.The proposed boathouse and wharf is to be located approximately perpendicular to the mean high water shoreline, the outer most edge toextend approximately 30 feet channelward therefrom.Project implementation would impact approximately 0.02 acres of water bottoms .Written comments, including suggestions for modifications or objections to the proposed work, stating reasons therefore , are being solicited from anyone having interest in this permit request .',\n",
       "        '{\\n  \"wetlands\": [\\n    {\\n      \"wetland_type\": \"water bottoms\",\\n      \"impact_quantity\": \"0.02\",\\n      \"impact_unit\": \"acres\",\\n      \"impact_duration\": \"unknown\",\\n      \"impact_type\": \"loss\"\\n    }\\n  ]\\n}']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wet_df_12_20_part1[[ 'noticeID', 'pdf_character', 'wetland_llm_dict']].sample(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning Impact types\n",
    "\n",
    "How to categorize the impact types?\n",
    "\n",
    "Which impact type *verbs* can be defined as losses of wetland?\n",
    "We can either hardcode it manually, or rely on the LLM.\n",
    "\n",
    "Even for hardcoding, we need to reduce the number of similar strings to a few standard phrases.\n",
    "- How? Semming, lemmatization, embedding/clustering. (compare to the knowledge base)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_impacts_21_24 = pd.read_parquet('wetland_impact_df_20.parquet')\n",
    "\n",
    "wet_impacts_12_17 = pd.read_parquet('wetland_impacts_pre_2020_1.parquet')\n",
    "\n",
    "wet_impacts_17_20 = pd.read_parquet('wetland_impacts_pre_2020_2.parquet')\n",
    "\n",
    "wet_impacts = pd.concat([wet_impacts_21_24, wet_impacts_17_20, wet_impacts_12_17], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import re\n",
    "# wet_impacts.impact_type.value_counts()\n",
    "# Example list of unique impact types\n",
    "unique_impact_types = list(wet_impacts.impact_type.unique())\n",
    "\n",
    "# Initialize lists for categories\n",
    "loss_list = []\n",
    "benefit_list = []\n",
    "uncategorized_list = []\n",
    "\n",
    "# Define keywords for each category with regular expression patterns\n",
    "loss_keywords = [r'\\bloss\\b', r'\\bfill', r'\\bdredg','impact', r'\\bdirect\\b', \n",
    "                 r'\\bexcavat', r'\\bremov', r'\\bclear', r'\\bdischarg']\n",
    "benefit_keywords = [r'\\brestor', r'\\bcreat', r'\\benhanc', r'\\bpreserv']\n",
    "\n",
    "# Categorize each impact type\n",
    "for impact in unique_impact_types:\n",
    "    if any(re.search(keyword, impact) for keyword in loss_keywords):\n",
    "        loss_list.append(impact)\n",
    "    elif any(re.search(keyword, impact) for keyword in benefit_keywords):\n",
    "        benefit_list.append(impact)\n",
    "    else:\n",
    "        uncategorized_list.append(impact)\n",
    "\n",
    "# # Now you have three lists: loss_list, benefit_list, uncategorized_list\n",
    "# wet_impacts[wet_impacts.impact_type.isin(uncategorized_list)].impact_type.value_counts().head(40)\n",
    "\n",
    "# Assuming loss_list, benefit_list, uncategorized_list are already populated as per your previous code\n",
    "\n",
    "impact_categs = {\n",
    "    \"LOSS\": loss_list,\n",
    "    \"BENEFIT\": benefit_list,\n",
    "    \"UNCATEGORIZED\": uncategorized_list\n",
    "}\n",
    "\n",
    "# Splitting the data\n",
    "loss_data = {\"LOSS\": impact_categs[\"LOSS\"]}\n",
    "benefit_data = {\"BENEFIT\": impact_categs[\"BENEFIT\"]}\n",
    "uncategorized_data = {\"UNCATEGORIZED\": impact_categs[\"UNCATEGORIZED\"]}\n",
    "\n",
    "# Dictionary containing each category and its data\n",
    "data_categories = {\n",
    "    \"loss\": loss_data,\n",
    "    \"benefit\": benefit_data,\n",
    "    \"uncategorized\": uncategorized_data\n",
    "}\n",
    "\n",
    "# Base name for file naming\n",
    "base_name = \"impact_type\"\n",
    "\n",
    "# Loop through each category and save to a separate JSON file\n",
    "for category, data in data_categories.items():\n",
    "    file_name = f\"{base_name}_{category}.json\"\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "        \n",
    "        \n",
    "# Function to categorize impact based on pre-categorized lists\n",
    "def categorize_impact(row):\n",
    "    impact = row['impact_type']\n",
    "    if impact in loss_list:\n",
    "        return \"LOSS\"\n",
    "    elif impact in benefit_list:\n",
    "        return \"BENEFIT\"\n",
    "    else:\n",
    "        return \"UNCATEGORIZED\"\n",
    "\n",
    "# Applying the function to the DataFrame\n",
    "wet_impacts['impact_type_clean'] = wet_impacts.apply(categorize_impact, axis=1)\n",
    "\n",
    "\n",
    "# # Initialize Porter Stemmer\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "# # Initialize lemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     # Convert to lowercase and remove punctuation\n",
    "#     text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "#     # Tokenize\n",
    "#     tokens = word_tokenize(text)\n",
    "    \n",
    "#     # Lemmatize each token\n",
    "# #     lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "  \n",
    "    \n",
    "#     # Stem each token\n",
    "#     stemmed = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "#     # Reconstruct the processed string\n",
    "#     return ' '.join(stemmed)\n",
    "\n",
    "# # Apply preprocessing to each item in the 'impact_type' column and create a new column\n",
    "# wet_impacts['st_impact_type'] = wet_impacts['impact_type'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "# # wet_impacts[wet_impacts.st_impact_type.str.contains('fill')].impact_type.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in `impact_type.json` (HYPERLINK) to categorize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning Wetland type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define keywords for wetland categorization\n",
    "wetland_keywords = [r'wetland', r'\\bjurisdiction', r'\\b404\\b', r'\\bwaters?\\b', \n",
    "                    r'\\bpalustrine\\b', r'\\bpfo\\b', r'\\bpem\\b', r'\\bpss\\b', r'\\bemergent\\b', \n",
    "                    r'\\bforested\\b', r'\\bwater\\s?bottoms?\\b', r'\\bestuarine\\b', \n",
    "                    r'\\bherbaceous\\b', r'\\bmarsh', r'\\bstream\\s?\\b', r'\\bhardwood\\s?\\b']\n",
    "\n",
    "# Initialize lists for categories\n",
    "wetland_list = []\n",
    "uncategorized_list = []\n",
    "\n",
    "# Extract unique wetland types\n",
    "unique_wetland_types = list(wet_impacts.wetland_type.unique())\n",
    "unique_wetland_types = [x.lower() for x in unique_wetland_types]\n",
    "# Categorize each wetland type\n",
    "for wetland_type in unique_wetland_types:\n",
    "    if any(re.search(keyword, wetland_type) for keyword in wetland_keywords):\n",
    "        wetland_list.append(wetland_type)\n",
    "    else:\n",
    "        uncategorized_list.append(wetland_type)\n",
    "\n",
    "# Create a dictionary with the two categories\n",
    "wetland_categs = {\n",
    "    \"WETLAND\": wetland_list,\n",
    "    \"UNCATEGORIZED\": uncategorized_list\n",
    "}\n",
    "\n",
    "# Save this dictionary as a JSON file\n",
    "with open('wetland_categ.json', 'w') as file:\n",
    "    json.dump(wetland_categs, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in `wetland_categ.json` to categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wetland_type</th>\n",
       "      <th>impact_quantity</th>\n",
       "      <th>impact_unit</th>\n",
       "      <th>impact_duration</th>\n",
       "      <th>impact_type</th>\n",
       "      <th>noticeID</th>\n",
       "      <th>impact_type_clean</th>\n",
       "      <th>wetland_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jurisdictional wetlands</td>\n",
       "      <td>9.85</td>\n",
       "      <td>acres</td>\n",
       "      <td>permanent</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_6585</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dock slip</td>\n",
       "      <td>74,643</td>\n",
       "      <td>cubic yards</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dredging</td>\n",
       "      <td>Notice_NO_6578</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Section 10 waters</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>structures</td>\n",
       "      <td>Notice_NO_6594</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>2.79</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_6589</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>0.61</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_6589</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>forested wetlands</td>\n",
       "      <td>0.26</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_2484</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>waters</td>\n",
       "      <td>Mobile Bay</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_4848</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>12.43</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_4849</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>jurisdictional waters</td>\n",
       "      <td>0.66</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_467</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>oyster reefs</td>\n",
       "      <td>6.02</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>construction</td>\n",
       "      <td>Notice_NO_6077</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12929 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 wetland_type impact_quantity  impact_unit impact_duration  \\\n",
       "0     jurisdictional wetlands            9.85        acres       permanent   \n",
       "1                   dock slip          74,643  cubic yards         unknown   \n",
       "2           Section 10 waters         unknown      unknown         unknown   \n",
       "3                    wetlands            2.79        acres         unknown   \n",
       "4                    wetlands            0.61        acres         unknown   \n",
       "...                       ...             ...          ...             ...   \n",
       "3867        forested wetlands            0.26        acres         unknown   \n",
       "3868                   waters      Mobile Bay      unknown         unknown   \n",
       "3869                 wetlands           12.43        acres         unknown   \n",
       "3870    jurisdictional waters            0.66        acres         unknown   \n",
       "3871             oyster reefs            6.02        acres         unknown   \n",
       "\n",
       "       impact_type        noticeID impact_type_clean  wetland_clean  \n",
       "0             loss  Notice_NO_6585              LOSS        wetland  \n",
       "1         dredging  Notice_NO_6578              LOSS  uncategorized  \n",
       "2       structures  Notice_NO_6594     UNCATEGORIZED        wetland  \n",
       "3             fill  Notice_NO_6589              LOSS        wetland  \n",
       "4             fill  Notice_NO_6589              LOSS        wetland  \n",
       "...            ...             ...               ...            ...  \n",
       "3867          loss  Notice_NO_2484              LOSS        wetland  \n",
       "3868          loss  Notice_NO_4848              LOSS        wetland  \n",
       "3869          fill  Notice_NO_4849              LOSS        wetland  \n",
       "3870          fill   Notice_NO_467              LOSS        wetland  \n",
       "3871  construction  Notice_NO_6077     UNCATEGORIZED  uncategorized  \n",
       "\n",
       "[12929 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the wetland categories from the JSON file\n",
    "with open('wetland_categ.json', 'r') as file:\n",
    "    wetland_categs = json.load(file)\n",
    "\n",
    "    \n",
    "# Function to determine wetland_clean\n",
    "def determine_wetland_clean(row):\n",
    "    wetland_type = row['wetland_type'].lower() \n",
    "    # Check if wetland_type is in the 'WETLAND' category and not 'unknown' or 'uncategorized'\n",
    "    if wetland_type in wetland_categs[\"WETLAND\"]:\n",
    "        return 'wetland'\n",
    "    else:\n",
    "        return 'uncategorized'\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "wet_impacts['wetland_clean'] = wet_impacts.apply(determine_wetland_clean, axis=1)\n",
    "wet_impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wetland_clean\n",
       "wetland          6905\n",
       "uncategorized    6024\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wet_impacts.wetland_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wetland_type</th>\n",
       "      <th>impact_quantity</th>\n",
       "      <th>impact_unit</th>\n",
       "      <th>impact_duration</th>\n",
       "      <th>impact_type</th>\n",
       "      <th>noticeID</th>\n",
       "      <th>impact_type_clean</th>\n",
       "      <th>wetland_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jurisdictional wetlands</td>\n",
       "      <td>9.85</td>\n",
       "      <td>acres</td>\n",
       "      <td>permanent</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_6585</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dock slip</td>\n",
       "      <td>74,643</td>\n",
       "      <td>cubic yards</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dredging</td>\n",
       "      <td>Notice_NO_6578</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Section 10 waters</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>structures</td>\n",
       "      <td>Notice_NO_6594</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>2.79</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_6589</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>0.61</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_6589</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>forested wetlands</td>\n",
       "      <td>0.26</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_2484</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>waters</td>\n",
       "      <td>Mobile Bay</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_4848</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>12.43</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_4849</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>jurisdictional waters</td>\n",
       "      <td>0.66</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_467</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>oyster reefs</td>\n",
       "      <td>6.02</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>construction</td>\n",
       "      <td>Notice_NO_6077</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>uncategorized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12929 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 wetland_type impact_quantity  impact_unit impact_duration  \\\n",
       "0     jurisdictional wetlands            9.85        acres       permanent   \n",
       "1                   dock slip          74,643  cubic yards         unknown   \n",
       "2           Section 10 waters         unknown      unknown         unknown   \n",
       "3                    wetlands            2.79        acres         unknown   \n",
       "4                    wetlands            0.61        acres         unknown   \n",
       "...                       ...             ...          ...             ...   \n",
       "3867        forested wetlands            0.26        acres         unknown   \n",
       "3868                   waters      Mobile Bay      unknown         unknown   \n",
       "3869                 wetlands           12.43        acres         unknown   \n",
       "3870    jurisdictional waters            0.66        acres         unknown   \n",
       "3871             oyster reefs            6.02        acres         unknown   \n",
       "\n",
       "       impact_type        noticeID impact_type_clean  wetland_clean  \n",
       "0             loss  Notice_NO_6585              LOSS        wetland  \n",
       "1         dredging  Notice_NO_6578     UNCATEGORIZED  uncategorized  \n",
       "2       structures  Notice_NO_6594     UNCATEGORIZED        wetland  \n",
       "3             fill  Notice_NO_6589              LOSS        wetland  \n",
       "4             fill  Notice_NO_6589              LOSS        wetland  \n",
       "...            ...             ...               ...            ...  \n",
       "3867          loss  Notice_NO_2484              LOSS        wetland  \n",
       "3868          loss  Notice_NO_4848              LOSS        wetland  \n",
       "3869          fill  Notice_NO_4849              LOSS        wetland  \n",
       "3870          fill   Notice_NO_467              LOSS        wetland  \n",
       "3871  construction  Notice_NO_6077     UNCATEGORIZED  uncategorized  \n",
       "\n",
       "[12929 rows x 8 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Categorize impacts according to both wetland and impact_type\n",
    "def categorize_impact(row):\n",
    "    if row['impact_type_clean'] == 'LOSS' and row['wetland_clean'] == 'wetland':\n",
    "        return 'LOSS'\n",
    "    elif row['impact_type_clean'] == 'BENEFIT' and row['wetland_clean'] == 'wetland':\n",
    "        return 'BENEFIT'\n",
    "    return 'UNCATEGORIZED'  # Default category if conditions are not met\n",
    "\n",
    "# Apply the modified function to the DataFrame\n",
    "wet_impacts['impact_type_clean'] = wet_impacts.apply(categorize_impact, axis=1)\n",
    "wet_impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "impact_type_clean\n",
       "UNCATEGORIZED    7253\n",
       "LOSS             5384\n",
       "BENEFIT           292\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wet_impacts.impact_type_clean.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning Impact units\n",
    "\n",
    "\n",
    "* Categorize units into a few standardized ones: acre, sq. feet, miles, cubic years, feet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "impact_unit_clean\n",
       "acres          7618\n",
       "feet           1584\n",
       "square feet    1081\n",
       "unknown         903\n",
       "other           821\n",
       "cubic yards     816\n",
       "miles           106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def standardize_unit(unit):\n",
    "    patterns = {\n",
    "        'acres': re.compile(r'\\bacres?\\b', re.IGNORECASE),\n",
    "        'square feet': re.compile(r'\\bsq\\.?\\s*ft\\.?|\\bft2\\b|\\bft²\\b|\\bsquare\\s*feet\\b|\\bfeet²\\b|\\bsq\\.?\\s*feet\\.?\\b', re.IGNORECASE),\n",
    "        'feet': re.compile(r'\\bfeet\\b|\\bfoot\\b|\\bft\\b', re.IGNORECASE),\n",
    "        'cubic yards': re.compile(r'\\bcubic\\s*yards\\b|\\byd3\\b|\\byards³\\b|\\byards3\\b|\\bcy\\b|\\bcubic-yards\\b', re.IGNORECASE),\n",
    "        'miles': re.compile(r'\\bmiles?\\b', re.IGNORECASE)\n",
    "    }\n",
    "\n",
    "    for standardized_unit, pattern in patterns.items():\n",
    "        if pattern.search(unit):\n",
    "            return standardized_unit\n",
    "\n",
    "    return unit\n",
    "\n",
    "wet_impacts['impact_unit_clean'] = wet_impacts['impact_unit'].apply(lambda x: standardize_unit(x.lower().strip()))\n",
    "\n",
    "# List of specified units\n",
    "clean_units = ['acres', 'linear feet', 'square feet', 'unknown', 'cubic yards', 'feet', 'miles']\n",
    "\n",
    "# Replace values not in specified categories with 'other'\n",
    "wet_impacts['impact_unit_clean'] = wet_impacts['impact_unit_clean'].apply(lambda x: x if x in \n",
    "                                                                                        clean_units else 'other')\n",
    "\n",
    "\n",
    "wet_impacts.impact_unit_clean.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with old\n",
    "\n",
    "# wet_impacts_old = pd.read_csv(r'D:\\Work\\Georgetown\\acad\\mdi\\usace\\usace_analysis\\data_download\\wetland_final_df.csv')\n",
    "\n",
    "# wet_impacts_old.impact_unit.value_counts()\n",
    "\n",
    "# wet_impacts.impact_unit.value_counts()\n",
    "\n",
    "# wet_impacts_old.wetland_type.value_counts()\n",
    "\n",
    "# wet_impacts.wetland_type.value_counts()\n",
    "# wet_impacts_old.impact_type.value_counts()\n",
    "\n",
    "# wet_impacts.impact_type.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wetland impact errors\n",
    "\n",
    "Explicitly test for the following types of errors. These 'patterns' were spotted by looking at some random results.\n",
    "\n",
    "- Double counting\n",
    "\n",
    "- Multi-unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notices with likely double counts: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to convert each group into a JSON string\n",
    "def group_to_json(group):\n",
    "    group_dict = group.drop('noticeID', axis=1).to_dict(orient='records')\n",
    "    return json.dumps({'wetlands': group_dict})\n",
    "\n",
    "# Group by noticeID and apply the function\n",
    "wdf = wet_impacts.groupby('noticeID').apply(group_to_json).reset_index(name='json_data')\n",
    "\n",
    "# Assuming df is your DataFrame with a column 'json_data' containing JSON strings\n",
    "\n",
    "# Function to parse JSON and return the number of objects\n",
    "def count_impacts(json_str):\n",
    "    try:\n",
    "        wetlands = json.loads(json_str)['wetlands']\n",
    "        return len(wetlands)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Add the impact_count column\n",
    "wdf['impact_count'] = wdf['json_data'].apply(count_impacts)\n",
    "\n",
    "# Function to analyze impacts and set doub_count\n",
    "def analyze_and_set_doub_count(row):\n",
    "    try:\n",
    "        wetlands = json.loads(row['json_data'])['wetlands']\n",
    "        quantities = [w['impact_quantity'] for w in wetlands if 'impact_quantity' in w and w['impact_quantity'] is not None]\n",
    "        max_impact = max(quantities, default=0)\n",
    "        sum_of_others = sum(q for q in quantities if q != max_impact)\n",
    "\n",
    "        # Allowing a 1-2% margin of error\n",
    "        if max_impact != 0 and abs(max_impact - sum_of_others) / max_impact <= 0.01:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Add the doub_count column\n",
    "wdf['doub_count'] = wdf.apply(analyze_and_set_doub_count, axis=1)\n",
    "\n",
    "error_notices1 = list(wdf[wdf['doub_count']==1].noticeID.unique())\n",
    "\n",
    "print('Number of notices with likely double counts:', len(error_notices1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notices with Multi unit errors: 246\n"
     ]
    }
   ],
   "source": [
    "wdf = wdf.merge(val_df[['noticeID', 'pdf_character']], on='noticeID', how='inner')\n",
    "\n",
    "# Assuming df is your DataFrame and it has a column named 'pdf_character'\n",
    "\n",
    "# Regular expressions for different units\n",
    "units_regex = {\n",
    "    re.compile(r'\\bacr(es|e)?\\b', re.IGNORECASE): 'acre',\n",
    "    re.compile(r'\\bsquare feet\\b|\\bsq\\.? feet\\b|\\bsq\\.? ft\\b|\\bsquare foot\\b', re.IGNORECASE): 'square feet'}\n",
    "\n",
    "\n",
    "def check_multi_units(text):\n",
    "    try:\n",
    "        found_categories = set()\n",
    "        for regex, category in units_regex.items():\n",
    "            if regex.search(text):\n",
    "                found_categories.add(category)\n",
    "    except: return 0\n",
    "    return 1 if len(found_categories) > 1 else 0\n",
    "\n",
    "\n",
    "# Apply the function to create the multi_unit column\n",
    "wdf['multi_unit'] = wdf['pdf_character'].apply(check_multi_units)\n",
    "\n",
    "# get unique noticeIDs\n",
    "error_notices2 = list(wdf[wdf['multi_unit']==1].noticeID.unique())\n",
    "#append both lists\n",
    "error_notices = list(set(error_notices1+ error_notices2))\n",
    "print('Number of notices with Multi unit errors:', len(error_notices2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cleaning Impact quantity\n",
    "\n",
    "\n",
    "Replace any commas, get rid of 0 impacts, convert to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting the number, handling commas, decimals, NaNs, and blanks\n",
    "wet_impacts['impact_qty_num'] = wet_impacts['impact_quantity'].str.extract(r'([\\d,.]+)').replace(',', '', regex=True)\n",
    "wet_impacts['impact_qty_num'] = pd.to_numeric(wet_impacts['impact_qty_num'], errors='coerce', downcast='float')\n",
    "\n",
    "#replace 0.00 values\n",
    "wet_impacts['impact_qty_num'] = wet_impacts['impact_qty_num'].replace(0.00, np.nan)\n",
    "\n",
    "# wet_impacts[wet_impacts.impact_quantity.str.contains(r'([\\d,.]+)', regex=True)][['impact_qty_num', 'impact_quantity']]\n",
    "\n",
    "# # export\n",
    "# wetland_final_df = wet_impacts[['noticeID', 'wetland_type', 'impact_duration', 'impact_qty_num',\n",
    "#                                 'impact_unit_clean', 'impact_type', 'impact_type_clean']]\n",
    "# wetland_final_df = wetland_final_df.rename(columns={'impact_qty_num': 'impact_quantity', 'impact_unit_clean': 'impact_unit'})\n",
    "\n",
    "# # wetland_final_df.to_csv('wetland_final_df_ft_16Jan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_impacts['error_likely'] = wet_impacts['noticeID'].isin(error_notices).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final export\n",
    "\n",
    "`wetland_impact_clean.parquet` will be loaded and merged to the main dataset into the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_impacts.to_parquet('wetland_impact_clean.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wetland_type</th>\n",
       "      <th>impact_quantity</th>\n",
       "      <th>impact_unit</th>\n",
       "      <th>impact_duration</th>\n",
       "      <th>impact_type</th>\n",
       "      <th>noticeID</th>\n",
       "      <th>impact_type_clean</th>\n",
       "      <th>wetland_clean</th>\n",
       "      <th>impact_unit_clean</th>\n",
       "      <th>impact_qty_num</th>\n",
       "      <th>error_likely</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jurisdictional wetlands</td>\n",
       "      <td>9.85</td>\n",
       "      <td>acres</td>\n",
       "      <td>permanent</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_6585</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "      <td>acres</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dock slip</td>\n",
       "      <td>74,643</td>\n",
       "      <td>cubic yards</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dredging</td>\n",
       "      <td>Notice_NO_6578</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>cubic yards</td>\n",
       "      <td>74643.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Section 10 waters</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>structures</td>\n",
       "      <td>Notice_NO_6594</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>wetland</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>2.79</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_6589</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "      <td>acres</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>0.61</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_6589</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "      <td>acres</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>forested wetlands</td>\n",
       "      <td>0.26</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_2484</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "      <td>acres</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>waters</td>\n",
       "      <td>Mobile Bay</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>loss</td>\n",
       "      <td>Notice_NO_4848</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>wetlands</td>\n",
       "      <td>12.43</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_4849</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "      <td>acres</td>\n",
       "      <td>12.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>jurisdictional waters</td>\n",
       "      <td>0.66</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fill</td>\n",
       "      <td>Notice_NO_467</td>\n",
       "      <td>LOSS</td>\n",
       "      <td>wetland</td>\n",
       "      <td>acres</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>oyster reefs</td>\n",
       "      <td>6.02</td>\n",
       "      <td>acres</td>\n",
       "      <td>unknown</td>\n",
       "      <td>construction</td>\n",
       "      <td>Notice_NO_6077</td>\n",
       "      <td>UNCATEGORIZED</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>acres</td>\n",
       "      <td>6.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12929 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 wetland_type impact_quantity  impact_unit impact_duration  \\\n",
       "0     jurisdictional wetlands            9.85        acres       permanent   \n",
       "1                   dock slip          74,643  cubic yards         unknown   \n",
       "2           Section 10 waters         unknown      unknown         unknown   \n",
       "3                    wetlands            2.79        acres         unknown   \n",
       "4                    wetlands            0.61        acres         unknown   \n",
       "...                       ...             ...          ...             ...   \n",
       "3867        forested wetlands            0.26        acres         unknown   \n",
       "3868                   waters      Mobile Bay      unknown         unknown   \n",
       "3869                 wetlands           12.43        acres         unknown   \n",
       "3870    jurisdictional waters            0.66        acres         unknown   \n",
       "3871             oyster reefs            6.02        acres         unknown   \n",
       "\n",
       "       impact_type        noticeID impact_type_clean  wetland_clean  \\\n",
       "0             loss  Notice_NO_6585              LOSS        wetland   \n",
       "1         dredging  Notice_NO_6578     UNCATEGORIZED  uncategorized   \n",
       "2       structures  Notice_NO_6594     UNCATEGORIZED        wetland   \n",
       "3             fill  Notice_NO_6589              LOSS        wetland   \n",
       "4             fill  Notice_NO_6589              LOSS        wetland   \n",
       "...            ...             ...               ...            ...   \n",
       "3867          loss  Notice_NO_2484              LOSS        wetland   \n",
       "3868          loss  Notice_NO_4848              LOSS        wetland   \n",
       "3869          fill  Notice_NO_4849              LOSS        wetland   \n",
       "3870          fill   Notice_NO_467              LOSS        wetland   \n",
       "3871  construction  Notice_NO_6077     UNCATEGORIZED  uncategorized   \n",
       "\n",
       "     impact_unit_clean  impact_qty_num  error_likely  \n",
       "0                acres            9.85             0  \n",
       "1          cubic yards        74643.00             0  \n",
       "2              unknown             NaN             0  \n",
       "3                acres            2.79             0  \n",
       "4                acres            0.61             0  \n",
       "...                ...             ...           ...  \n",
       "3867             acres            0.26             0  \n",
       "3868           unknown             NaN             0  \n",
       "3869             acres           12.43             0  \n",
       "3870             acres            0.66             0  \n",
       "3871             acres            6.02             0  \n",
       "\n",
       "[12929 rows x 11 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wet_impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## END\n",
    "\n",
    "\n",
    "## Project categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_embed(input_text, API_KEY):\n",
    "    \"\"\"\n",
    "    This function initializes an OpenAI client with the provided API key and then generates embeddings \n",
    "    for the specified input text using the 'text-embedding-ada-002' model. It counts the number of tokens \n",
    "    in the input text, generates embeddings, and extracts the embedding vector from the response.\n",
    "\n",
    "    Parameters:\n",
    "    input_text (str): The text for which embeddings are to be generated.\n",
    "    API_KEY (str): The API key for authentication with the OpenAI API.\n",
    "\n",
    "    Returns:\n",
    "    A tuple containing two elements:\n",
    "           1. token_count (int): The number of tokens in the input text.\n",
    "           2. vector (list or str): The embedding vector if successful, or an error message if an exception occurs.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Captures and returns any exceptions that occur during the API call or processing of the response.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize client\n",
    "    client = OpenAI(\n",
    "    api_key=API_KEY,  \n",
    "    )\n",
    "    try:\n",
    "        openai.api_key= API_KEY\n",
    "        encoding = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "        #count number of tokens\n",
    "        token_count =  len(encoding.encode(input_text))\n",
    "\n",
    "        #generate embeddings  \n",
    "        response = client.embeddings.create(input=input_text, model='text-embedding-ada-002')\n",
    "        \n",
    "        embeddings = response.model_dump_json(indent=0)\n",
    "        \n",
    "    #     embeddings = embeddings.values[0]\n",
    "        \n",
    "        # Load the JSON data\n",
    "        data = json.loads(embeddings)\n",
    "\n",
    "        # Access and extract the vector\n",
    "        vector = data[\"data\"][0][\"embedding\"]\n",
    "        return token_count, vector\n",
    "    \n",
    "    except Exception as e:\n",
    "            # Return the error message in place of embeddings\n",
    "        return token_count, f\"Error: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = [\"\"\"Commercial developments - Include non-manufacturing business establishments \n",
    "such as department stores, hardware stores, retail outlets, grocery stores, car washes, corner stores, \n",
    "office buildings, strip malls, shopping centers, movie theaters, hotels/motels/inns, hospitals, etc\"\"\",\n",
    "\n",
    "\"\"\"Drainage features - Drainage features  include gravity drainage channels and canals; water control structures; and pump stations and associated structures.\"\"\",\n",
    "\n",
    "\"\"\"Industrial developments - Industrial developments are defined as facilities used to produce goods in connection with, \n",
    "or as part of, a process or system.  Such developments incl ude refineries, steel mills, \n",
    "shipyards, fabrication facilities, food processing facilities, bulk loading facilities,\n",
    "landfills, water treatment systems, etc.\"\"\",\n",
    "\n",
    "\"\"\"Oil and Gas facilities - Oil and Gas facilities located within the coastal zone include \n",
    "(for the purposes of this guide) well sites, production facilities and storage facilities.  \"\"\",\n",
    "\n",
    "\"\"\"Pipelines and flowlines - Pipelines and flowlines (hereafter referred to as “lines”) are linear features installed for \n",
    "the purpose of transporting materials from one location to another.  Lines can be of any diameter \n",
    "and length and any type of liquid or gaseous material can be transported within them.\"\"\", \n",
    "\n",
    "\"\"\"Recreation facilities  - Recreation facilities include, but are not limited to, parks; visitor centers; picnic areas; ball \n",
    "fields; playgrounds; public golf courses; community swimming pools, tennis courts and basketball courts; \n",
    "and nature, hiking and bike trails.\"\"\",\n",
    "\n",
    "\"\"\"Residential subdivisions - residential subdivisions  as multi -house/unit residential developments.\"\"\" ,\n",
    "\n",
    "\"\"\"Transportation - Transportation features include roads, bridges and ferries, construction and maintenance of \n",
    "which typically are undertaken by state or local governmental bodies, or in the case of ferries, \n",
    "private companies.  This guide is focused more transportation features constructe d by municipal entities. \n",
    "For the purposes of application processing, air and rail developments should refer to our  \n",
    "commercial or industrial developments guides depending on the nature of the activity; boat\n",
    "traffic should refer to our M arinas, Ports or Recreational Facilities guides depending on \n",
    "the nature of the activity; and bike and foot trails should refer to  the R ecreational Facilities  guide.\"\"\",\n",
    "\n",
    "\"\"\"Utility - Utility activities include potable water facilities and lines, sewerage facilities and lines, gas and electricity facilities \n",
    "and lines, phone lines, cable lines and fiber optic lines.\"\"\",\n",
    "\n",
    "\"\"\"Ports  - a port as an industrial type, water -based cargo transfer facility \"\"\",\n",
    "\n",
    "\"\"\"Levee - A levee is defined as an embankment or wall to control or prevent water movement, to retain water \n",
    "or other material, or to raise a road or other lineal use above normal or flood water levels.  \n",
    "Examples include levees, dikes, flood walls and embankments of any kind.\"\"\",\n",
    "\n",
    "\"\"\"Marina - marinas  as any type of development focused on providing water access and docking services to the boating \n",
    "community.   Marina amenities  include fueling stations, pump -out stations, wash stations, ice houses, seafood processing \n",
    "facilities (including fish cleaning stations), stores, bait shops, restaurants, lodging, etc.  Shipyards and other exclusive\n",
    "retail/service type facilities such as boat retail and/or repair are not considered marinas for the purposes of this guide.\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial developments - Include non-manufact...</td>\n",
       "      <td>Commercial developments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drainage features - Drainage features  include...</td>\n",
       "      <td>Drainage features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Industrial developments - Industrial developme...</td>\n",
       "      <td>Industrial developments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oil and Gas facilities - Oil and Gas facilitie...</td>\n",
       "      <td>Oil and Gas facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pipelines and flowlines - Pipelines and flowli...</td>\n",
       "      <td>Pipelines and flowlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recreation facilities  - Recreation facilities...</td>\n",
       "      <td>Recreation facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Residential subdivisions - residential subdivi...</td>\n",
       "      <td>Residential subdivisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transportation - Transportation features inclu...</td>\n",
       "      <td>Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Utility - Utility activities include potable w...</td>\n",
       "      <td>Utility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ports  - a port as an industrial type, water -...</td>\n",
       "      <td>Ports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Levee - A levee is defined as an embankment or...</td>\n",
       "      <td>Levee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Marina - marinas  as any type of development f...</td>\n",
       "      <td>Marina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 desc  \\\n",
       "0   Commercial developments - Include non-manufact...   \n",
       "1   Drainage features - Drainage features  include...   \n",
       "2   Industrial developments - Industrial developme...   \n",
       "3   Oil and Gas facilities - Oil and Gas facilitie...   \n",
       "4   Pipelines and flowlines - Pipelines and flowli...   \n",
       "5   Recreation facilities  - Recreation facilities...   \n",
       "6   Residential subdivisions - residential subdivi...   \n",
       "7   Transportation - Transportation features inclu...   \n",
       "8   Utility - Utility activities include potable w...   \n",
       "9   Ports  - a port as an industrial type, water -...   \n",
       "10  Levee - A levee is defined as an embankment or...   \n",
       "11  Marina - marinas  as any type of development f...   \n",
       "\n",
       "                         cat  \n",
       "0    Commercial developments  \n",
       "1          Drainage features  \n",
       "2    Industrial developments  \n",
       "3     Oil and Gas facilities  \n",
       "4    Pipelines and flowlines  \n",
       "5     Recreation facilities   \n",
       "6   Residential subdivisions  \n",
       "7             Transportation  \n",
       "8                    Utility  \n",
       "9                     Ports   \n",
       "10                     Levee  \n",
       "11                    Marina  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Step 1: Prepare the DataFrame\n",
    "categories = [desc.split(\" - \")[0] for desc in descr]\n",
    "descriptions = [desc for desc in descr]\n",
    "df = pd.DataFrame({'desc': descriptions, 'cat': categories})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your API key\n",
    "API_KEY = OPENAI_API_KEY \n",
    "#= \"sk-\"\n",
    "\n",
    "\n",
    "# Step 3: Add Embeddings to the DataFrame\n",
    "df['cat_embed'] = df['desc'].apply(lambda x: openai_embed(x, API_KEY)[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pay attention to data structures. One is a list inside a string '[a,b,c]', or technically, just one string. So is the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df['char_embed'] = emb_df.embeddings.apply(ast.literal_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarities: 100%|█████████████████████████████████████████████████| 6506/6506 [00:00<00:00, 19421.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Normalize embeddings for cosine similarity calculation\n",
    "def normalize_embeddings(embeddings):\n",
    " # Apply ast.literal_eval to each string in the array to convert it to a list of floats\n",
    "#     embeddings = [ast.literal_eval(emb) if isinstance(emb, str) else emb for emb in embeddings]\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    return embeddings / norms\n",
    "\n",
    "# Extract and normalize embeddings\n",
    "df_embeddings = np.vstack(df['cat_embed'].apply(np.array))\n",
    "emb_df_embeddings = np.vstack(emb_df['char_embed'].apply(np.array))\n",
    "\n",
    "normalized_df_embeddings = normalize_embeddings(df_embeddings)\n",
    "normalized_emb_df_embeddings = normalize_embeddings(emb_df_embeddings)\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(normalized_emb_df_embeddings, normalized_df_embeddings)\n",
    "\n",
    "# Initialize lists to store results\n",
    "cat_search = []\n",
    "scores = []\n",
    "\n",
    "# Iterate over each item in emb_df using tqdm for progress tracking\n",
    "for idx in tqdm(range(similarity_matrix.shape[0]), desc=\"Calculating similarities\"):\n",
    "    most_similar_idx = np.argmax(similarity_matrix[idx])\n",
    "    most_similar_score = similarity_matrix[idx, most_similar_idx]\n",
    "\n",
    "    # Append the corresponding category and score\n",
    "    cat_search.append(df.iloc[most_similar_idx]['cat'])\n",
    "    scores.append(most_similar_score)\n",
    "\n",
    "# Assign the results to emb_df\n",
    "emb_df['cat_search'] = cat_search\n",
    "emb_df['score'] = scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g_env",
   "language": "python",
   "name": "g_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
