{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSERT_KEY_HERE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"INSERT_KEY_HERE\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "openai.api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload training data to OpenAI\n",
    "\n",
    "This requires two `.jsonl` files - training and validation set, containing verified, high-quality input-output pairs. They should be in this same directory.\n",
    "\n",
    "(To learn how to create these files, refer to [other notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('finetune_openAI')\n",
    "\n",
    "training_file_name = \"usace_finetune_training.jsonl\"\n",
    "\n",
    "validation_file_name = \"usace_finetune_validation.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_file_name, \"rb\") as training_fd:\n",
    "    training_response = openai.files.create(\n",
    "        file=training_fd, purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "with open(validation_file_name, \"rb\") as validation_fd:\n",
    "    validation_response = openai.files.create(\n",
    "        file=validation_fd, purpose=\"fine-tune\"\n",
    "    )\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-sosHADFF8Aj4rCQyvmv2ONvY\n",
      "Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=\"usace-json\",\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-sosHADFF8Aj4rCQyvmv2ONvY\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-sosHADFF8Aj4rCQyvmv2ONvY\n",
      "Validating training file: file-0u7fSKiBaE2VczJEpF0ANEc0 and validation file: file-KsnzpUCeoh4uWgxG2QRkAEku\n",
      "Files validated, moving job to queued state\n",
      "Fine-tuning job started\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files validated, moving job to queued state\n",
      "Fine-tuning job started\n",
      "Step 1/156: training loss=0.76, validation loss=0.29\n",
      "Step 11/156: training loss=0.17, validation loss=0.23\n",
      "Step 21/156: training loss=0.04, validation loss=0.06\n",
      "Step 31/156: training loss=0.07, validation loss=0.05\n",
      "Step 41/156: training loss=0.02, validation loss=0.22\n",
      "Step 51/156: training loss=0.08, validation loss=0.18\n",
      "Step 61/156: training loss=0.24, validation loss=0.03\n",
      "Step 71/156: training loss=0.06, validation loss=0.03\n",
      "Step 81/156: training loss=0.38, validation loss=0.11\n",
      "Step 91/156: training loss=0.08, validation loss=0.11\n",
      "Step 101/156: training loss=0.03, validation loss=0.04\n",
      "Step 111/156: training loss=0.17, validation loss=0.04\n",
      "Step 121/156: training loss=0.09, validation loss=0.36\n",
      "Step 131/156: training loss=0.01, validation loss=0.17\n",
      "Step 141/156: training loss=0.21, validation loss=0.03\n",
      "Step 151/156: training loss=0.01, validation loss=0.03\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0613:eidc-mdi-georgetown:usace-json:8ait0mXa\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None: \n",
    "    raise RuntimeError(\"Fine-tuned model ID not found. Your job has likely not been completed yet.\")\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_id = 'ft:gpt-3.5-turbo-0613:eidc-mdi-georgetown:usace-json:8ait0mXa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"'The applicant requests authorization to perform maintenance dredging in previously dredged areas in Yards 2 - 6 and 8 of the Modern American Recycling & Repair Service ( MARRS ) property. The dredging will consist of the mechanical removal of 459,796 cubic yards of material from 571,189 square feet (13.1 acres) of river bottoms located to the west of the Mobile River federal navigation channel.Dredge depths with be between - 25 to -60 feet relative to Mean Lower Low Water ( MLLW ) at each of the 8 proposed dredge sites. The dredged materials are proposed to be disposed at either Galliard Island or the Mobile Ocean Dredged Material Disposal Site (ODMDS), depending on regulatory approval. The details of each dredge area can be found in the attached drawings.\"\"\"\n",
    "text = \"\"\"The applicant seeks authorization to fill 2,000 cubic yards (0.38 acres) of wetlands and 53.52 acres of waters (10.93 acres of dredge; 42.59 acres of fill) of ditches) for construction of a single family residential development. The plan proposes to preserve the remaining 7.86 acres of wetlands and 23.43 acres of waters on site.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user    The applicant seeks authorization to fill 2,00...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tdf = pd.DataFrame([text], columns=['user'])\n",
    "\n",
    "test_row = tdf.iloc[0]\n",
    "\n",
    "test_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt2 = \"\"\"Your task is to Extract information from a project description to create a structured dictionary, following the provided JSON schema. Focus on identifying wetland impacts based on the given criteria.\n",
    "\n",
    "JSON Schema Overview:\n",
    "\n",
    "wetland_type: Type or descriptor of the wetland (e.g., swamp, marsh).\n",
    "impact_quantity: Numeric value of the impacted area.\n",
    "impact_unit: Units of measurement (acres, sq. feet, linear feet).\n",
    "impact_duration: Duration of impact (permanent, temporary, unknown).\n",
    "impact_type: Nature of impact (harmful, beneficial, unknown).\n",
    "Instructions:\n",
    "\n",
    "Identify Wetlands and Impacts: Look for sentences detailing the wetland/water/land type and the impacts. Record the type, quantity, and unit. There may be multiple impacts.\n",
    "Determine Impact Duration: Mark 'permanent' or 'temporary' if mentioned with wetland type and area; else, write 'unknown'.\n",
    "Assess Impact Type: Identify if the impact is harmful, beneficial, or unknown.\n",
    "Avoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.\n",
    "Create a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\n",
    "Example Input:\n",
    "'The project will affect 3.5 acres of marshland permanently, leading to habitat loss...'\n",
    "\n",
    "Expected Output:\n",
    "{'wetlands': [{'wetland_type': 'marshland', 'impact_quantity': '3.5', 'impact_unit': 'acres', 'impact_duration': 'permanent', 'impact_type': 'loss'}]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"Task: Extract information from a project description to create a structured dictionary, following the provided JSON schema. Focus on identifying wetland impacts based on the given criteria.\\n\\nJSON Schema Overview:\\n\\nwetland_type: Type or descriptor of the wetland (e.g., swamp, marsh).\\nimpact_quantity: Numeric value of the impacted area.\\nimpact_unit: Units of measurement (acres, sq. feet, linear feet).\\nimpact_duration: Duration of impact (permanent, temporary, unknown).\\nimpact_type: Nature of impact (harmful, beneficial, unknown).\\nInstructions:\\n\\nIdentify Wetlands and Impacts: Look for sentences detailing the wetland/water/land type and the impacts. Record the type, quantity, and unit. There may be multiple impacts.\\nDetermine Impact Duration: Mark 'permanent' or 'temporary' if mentioned with wetland type and area; else, write 'unknown'.\\nAssess Impact Type: Identify if the impact is harmful, beneficial, or unknown.\\nAvoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.\\nCreate a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\\nExample Input:\\n'The project will affect 3.5 acres of marshland permanently, leading to habitat loss...'\\n\\nExpected Output:\\n{'wetlands': [{'wetland_type': 'marshland', 'impact_quantity': '3.5', 'impact_unit': 'acres', 'impact_duration': 'permanent', 'impact_type': 'loss'}]}\\n\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Project Description: The applicant seeks authorization to fill 2,000 cubic yards (0.38 acres) of wetlands and 53.52 acres of waters (10.93 acres of dredge; 42.59 acres of fill) of ditches) for construction of a single family residential development. The plan proposes to preserve the remaining 7.86 acres of wetlands and 23.43 acres of waters on site.\\n\\nExtracted Data: '}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wetlands': [{'wetland_type': 'wetlands', 'impact_quantity': '0.38', 'impact_unit': 'acres', 'impact_duration': 'unknown', 'impact_type': 'fill'}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_user_message(row):\n",
    "    return f\"\"\"Project Description: {row['user']}\\n\\nExtracted Data: \"\"\"\n",
    "\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \"content\": sys_prompt2})\n",
    "user_message = create_user_message(test_row)\n",
    "test_messages.append({\"role\": \"user\", \"content\": create_user_message(test_row)})\n",
    "test_messages\n",
    "\n",
    "# fine_tuned_model_id = 'gpt-3.5-turbo-0613'\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=fine_tuned_model_id, messages=test_messages, temperature=0.9, max_tokens=800\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate-to-area case (on fly) - FAILED!\n",
    "\n",
    "Catastrophic forgetting? General capabilities lost (adjust in prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The proposed project is to construct 217 single-family residential dwellings into Phase 4B of the Parks of Plaquemines subdivision. Construction activities include the homesites, roads, recreation features, natural buffers, and infrastructure. The project as proposed would directly impact 56.63 acres (permanently) of bottomland hardwood wetlands and 2,454 linear feet of non-tidal waters.\"\n",
    "tdf = pd.DataFrame([text], columns=['user'])\n",
    "\n",
    "test_row = tdf.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"Task: Extract information from a project description to create a structured dictionary, following the provided JSON schema. Focus on identifying wetland impacts based on the given criteria.\\n\\nJSON Schema Overview:\\n\\nwetland_type: Type or descriptor of the wetland (e.g., swamp, marsh).\\nimpact_quantity: Numeric value of the impacted area.\\nimpact_unit: Units of measurement (acres, sq. feet, linear feet).\\nimpact_duration: Duration of impact (permanent, temporary, unknown).\\nimpact_type: Nature of impact (harmful, beneficial, unknown).\\nInstructions:\\n\\nIdentify Wetlands and Impacts: Look for sentences detailing the wetland type and area impacted. Record the type, quantity, and unit.\\nDetermine Impact Duration: Mark 'permanent' or 'temporary' if mentioned with wetland type and area; else, write 'unknown'.\\nAssess Impact Type: Identify if the impact is harmful, beneficial, or unknown.\\nAvoid Double Counting: Be mindful of nested projects or phrases indicating multiple projects. Do not double count impacts.\\nCreate a Dictionary: For each wetland, provide its type, area, duration, and impact type in a structured format.\\nExample Input:\\n'The project will affect 3.5 acres of marshland permanently, leading to habitat loss...'\\n\\nExpected Output:\\n{'wetlands': [{'wetland_type': 'marshland', 'impact_quantity': '3.5', 'impact_unit': 'acres', 'impact_duration': 'permanent', 'impact_type': 'loss'}]}\\n\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Project Description: The proposed project is to construct 217 single-family residential dwellings into Phase 4B of the Parks of Plaquemines subdivision. Construction activities include the homesites, roads, recreation features, natural buffers, and infrastructure. The project as proposed would directly impact 56.63 acres (permanently) of bottomland hardwood wetlands and 2,454 linear feet of non-tidal waters.\\n\\nExtracted Data: '}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wetlands': [{'wetland_type': 'bottomland hardwood wetlands', 'impact_quantity': '56.63', 'impact_unit': 'acres', 'impact_duration': 'permanent', 'impact_type': 'loss'}, {'wetland_type': 'non-tidal waters', 'impact_quantity': '2,454', 'impact_unit': 'linear feet', 'impact_duration': 'unknown', 'impact_type': 'loss'}]}\n"
     ]
    }
   ],
   "source": [
    "def create_user_message(row):\n",
    "    return f\"\"\"Project Description: {row['user']}\\n\\nExtracted Data: \"\"\"\n",
    "\n",
    "\n",
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \"content\": sys_prompt2})\n",
    "user_message = create_user_message(test_row)\n",
    "test_messages.append({\"role\": \"user\", \"content\": create_user_message(test_row)})\n",
    "test_messages\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=500\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune + function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g_env",
   "language": "python",
   "name": "g_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
